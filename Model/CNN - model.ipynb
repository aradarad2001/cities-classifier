{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oiSCV1_ro_53"
   },
   "source": [
    "# Load data (functions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZIbOcfwJVoe0"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "meKBX-kAW3G0"
   },
   "outputs": [],
   "source": [
    "output_folder_path = '.'\n",
    "output_folder_path = Path(output_folder_path)\n",
    "img_width = 200\n",
    "img_height = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5yEDr-OV9Om"
   },
   "outputs": [],
   "source": [
    "def download_url(url, save_path=False, chunk_size=128):\n",
    "    \"downloads zip files to the folder that the notebook / python file is saved\"\n",
    "\n",
    "    if not save_path:\n",
    "        save_path = url.split('/')[-1]\n",
    "\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        with open(save_path, 'wb') as fd:\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                fd.write(chunk)\n",
    "    print(f\"file {save_path} succesfuly downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IfdvB9mdWEXt"
   },
   "outputs": [],
   "source": [
    "def unzip_to_structure(zipfile_path, output_root_folder):\n",
    "    \"\"\"unzips files to specified output root folder with structure: \n",
    "        <output_root_folder> / <set_type> / <city> / <img_key>.jpg\"\"\"\n",
    "\n",
    "    output_root_folder = Path(output_root_folder)\n",
    "    file_parts = str(Path(zipfile_path).stem).split('_')\n",
    "    city = file_parts[0]\n",
    "    set_type = file_parts[1]\n",
    "    for s in ['train','test','val']:   \n",
    "      with zipfile.ZipFile(zipfile_path, 'r') as zip_ref:\n",
    "        if set_type == s:\n",
    "          zip_ref.extractall(output_root_folder / s )\n",
    "    print(f\"images from '{zipfile_path}' succesfuly unziped to '{output_root_folder / s / city}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ifEBPyAQWIC_"
   },
   "outputs": [],
   "source": [
    "def get_images(cities,output_path=output_folder_path):\n",
    "  \"\"\"gets all images for defined cities\n",
    "  param:: cities, array of cities\n",
    "  param:: output_path \"\"\"\n",
    "  linkz = []\n",
    "\n",
    "  for city in cities:\n",
    "    for link in links:\n",
    "      if city in link:\n",
    "        linkz.append(link) \n",
    "  # download files to current directory\n",
    "\n",
    "  for link in linkz:\n",
    "      download_url(link)\n",
    "  \n",
    "  # unzip images to destination with format: \n",
    "  # <output_root_folder> / <set_type> / <city> / <img_key>.jpg\n",
    "  for link in linkz:\n",
    "      filename = Path(link).name\n",
    "      unzip_to_structure(filename,output_path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_links = pd.read_excel(\"Train_Files_links.xlsx\").values.tolist()\n",
    "val_links = pd.read_excel(\"Val_Files_links.xlsx\").values.tolist()\n",
    "links = train_links+val_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rHFgZPJenHHW"
   },
   "source": [
    "# Convolutional Neural Network (class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5207,
     "status": "ok",
     "timestamp": 1590482928130,
     "user": {
      "displayName": "Itamar Bergfreund",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg2MDwlO6hYcHvwKV5xDf-9d_7Omi9UVhJtoP3XdQ=s64",
      "userId": "13778766431941037401"
     },
     "user_tz": -180
    },
    "id": "0mE42AGFp6lA",
    "outputId": "ab672c34-116c-4726-e3f0-cb32a7641c6c"
   },
   "outputs": [],
   "source": [
    "# imports:\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4BATRsPinGJd"
   },
   "outputs": [],
   "source": [
    "# load class LeNet:\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(numChannels, imgRows, imgCols, numClasses,\n",
    "        activation=\"relu\", weightsPath=None):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        inputShape = (imgRows, imgCols, numChannels)\n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (numChannels, imgRows, imgCols)\n",
    "\n",
    "        # define the first set of CONV => ACTIVATION => POOL layers\n",
    "        model.add(Conv2D(100, 3, padding=\"same\",\n",
    "        input_shape=inputShape))\n",
    "        model.add(Activation(activation))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))      \n",
    "\n",
    "        # define the second set of CONV => ACTIVATION => POOL layers\n",
    "        model.add(Conv2D(50, 5, padding=\"same\"))\n",
    "        model.add(Activation(activation))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        # define the first FC => ACTIVATION layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(activation))\n",
    "        \n",
    "        # define the second FC layer\n",
    "        model.add(Dense(numClasses))\n",
    "        # lastly, define the soft-max classifier\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "        # if a weights path is supplied (inicating that the model was\n",
    "        # pre-trained), then load the weights\n",
    "        if weightsPath is not None:\n",
    "            model.load_weights(weightsPath)\n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QD_BuzL8-Ui1"
   },
   "source": [
    "## Prepare data sets for training (functions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYiCGfN8qwgl"
   },
   "outputs": [],
   "source": [
    "def create_train_val_test_set(dir_train='train', dir_val='val', dir_test='test'):\n",
    "\n",
    "    # get file lists\n",
    "    train_images = load_images_from_dir(dir_train)\n",
    "    val_images = load_images_from_dir(dir_val)\n",
    "    # test_images = load_images_from_dir(dir_val) ##commented for now\n",
    "\n",
    "\n",
    "    X_train, y_train = preprocess_images(train_images)\n",
    "    X_val, y_val = preprocess_images(val_images)\n",
    "    # X_test, y_test = preprocess_images(test_images)  ##commented for now\n",
    "\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X6cUVlD3sOaa"
   },
   "outputs": [],
   "source": [
    "def load_images_from_dir(directory):\n",
    "  \"\"\"Load all images from given directory and subdirectory\"\"\"\n",
    "\n",
    "  list_of_images = []\n",
    "\n",
    "  # get content of directory:\n",
    "  for d in os.listdir(directory):\n",
    "      if os.path.isdir(directory+ '/' + d):\n",
    "\n",
    "          # get files from subdirectories:\n",
    "          for f in os.listdir(directory+ '/' + d):\n",
    "              if not os.path.isdir(directory+ '/' + d + '/' + f):\n",
    "\n",
    "                  # create list of file paths:\n",
    "                  list_of_images.append(directory+ '/' + d + '/' + f)\n",
    "\n",
    "  return list_of_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cw4GeYIR6scO"
   },
   "outputs": [],
   "source": [
    "def preprocess_images(list_of_images):\n",
    "  \"\"\"preprocesses images: cut dashboard, resize\"\"\"\n",
    "  \n",
    "  X = [] # features\n",
    "  y = [] # labels\n",
    "\n",
    "  for i, img in enumerate(list_of_images):\n",
    "        try:\n",
    "            # cut and resize image:\n",
    "            X.append(cv2.resize(cv2.imread(img, cv2.IMREAD_COLOR)[:380, :], \n",
    "                                (img_width, img_height)).ravel())\n",
    "            # add city as label from the image path:\n",
    "            y.append(img.split('/')[-2])\n",
    "\n",
    "        except TypeError as e:\n",
    "            print(e,'on index',i)\n",
    "\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BhKN3iuV-o50"
   },
   "source": [
    "# -> code to run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 88470,
     "status": "ok",
     "timestamp": 1590483011618,
     "user": {
      "displayName": "Itamar Bergfreund",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg2MDwlO6hYcHvwKV5xDf-9d_7Omi9UVhJtoP3XdQ=s64",
      "userId": "13778766431941037401"
     },
     "user_tz": -180
    },
    "id": "fXs3CXKZ-rWZ",
    "outputId": "9e271582-9c4a-4d51-af75-36e4fd9a02f6"
   },
   "outputs": [],
   "source": [
    "# get data to current working dir (for changing dir got to top of the notebook):\n",
    "\n",
    "# available cities:\n",
    "my_cities = ['saopaulo','moscow','paris','manila','ottawa','austin','bangkok',\n",
    " 'sf','phoenix','melbourne','tokyo','goa','toronto','berlin', 'budapest',\n",
    " 'cph','helsinki','boston','amsterdam']\n",
    "\n",
    "# city selection:\n",
    "my_cities = ['saopaulo','toronto','bangkok']\n",
    "\n",
    "# download images from aws:\n",
    "get_images(my_cities) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCGzyngXzIIa"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-b868f8eddbd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# create data sets:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_train_val_test_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# checks:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-54565b114151>\u001b[0m in \u001b[0;36mcreate_train_val_test_set\u001b[1;34m(dir_train, dir_val, dir_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# get file lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_images_from_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mval_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_images_from_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# test_images = load_images_from_dir(dir_val) ##commented for now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-f884b90ed593>\u001b[0m in \u001b[0;36mload_images_from_dir\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;31m# get content of directory:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'train'"
     ]
    }
   ],
   "source": [
    "# create data sets:\n",
    "X_train, y_train, X_val, y_val = create_train_val_test_set()\n",
    "\n",
    "# checks:\n",
    "assert len(X_train) == len(y_train) \n",
    "assert len(X_val) == len(y_val)\n",
    "assert set(y_train) == set(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 186830,
     "status": "ok",
     "timestamp": 1590483110170,
     "user": {
      "displayName": "Itamar Bergfreund",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg2MDwlO6hYcHvwKV5xDf-9d_7Omi9UVhJtoP3XdQ=s64",
      "userId": "13778766431941037401"
     },
     "user_tz": -180
    },
    "id": "Hy2r7GFE8qoJ",
    "outputId": "2e191cde-9442-4692-98c6-0217351a6264"
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[3500].reshape(img_height, img_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 188240,
     "status": "ok",
     "timestamp": 1590483111671,
     "user": {
      "displayName": "Itamar Bergfreund",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg2MDwlO6hYcHvwKV5xDf-9d_7Omi9UVhJtoP3XdQ=s64",
      "userId": "13778766431941037401"
     },
     "user_tz": -180
    },
    "id": "qe6ZoSzJ_nO6",
    "outputId": "e8df8214-6b1d-4fee-fc7f-e746446ef4e1"
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[300].reshape(img_height, img_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e77293-gAAZg"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# set label encoder:\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "\n",
    "# transform labels:\n",
    "y_train = le.transform(y_train)\n",
    "y_val = le.transform(y_val)\n",
    "# y_test = le.transform(y_test)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train.reshape(-1, ), len(set(y_train)))\n",
    "y_val = np_utils.to_categorical(y_val.reshape(-1, ), len(set(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 188094,
     "status": "ok",
     "timestamp": 1590483111677,
     "user": {
      "displayName": "Itamar Bergfreund",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg2MDwlO6hYcHvwKV5xDf-9d_7Omi9UVhJtoP3XdQ=s64",
      "userId": "13778766431941037401"
     },
     "user_tz": -180
    },
    "id": "BkFo8LoCHKu7",
    "outputId": "2aaa9b96-5e7a-486d-c6ed-aad6d0b9a838"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], img_height,img_width, 3))\n",
    "X_val = X_val.reshape((X_val.shape[0], img_height,img_width, 3))\n",
    "# X_test = X_test.reshape((X_test.shape[0], img_width, img_height, 3))\n",
    "\n",
    "plt.imshow(X_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlKwFTrvDY2K"
   },
   "outputs": [],
   "source": [
    "# scale data to the range of [0, 1]:\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_val = X_val.astype(\"float32\") / 255.0\n",
    "# X_test = X_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 203001,
     "status": "ok",
     "timestamp": 1590483126643,
     "user": {
      "displayName": "Itamar Bergfreund",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg2MDwlO6hYcHvwKV5xDf-9d_7Omi9UVhJtoP3XdQ=s64",
      "userId": "13778766431941037401"
     },
     "user_tz": -180
    },
    "id": "QqA0t9SoFhVD",
    "outputId": "f51b1fe4-052b-465a-e3ed-8d1adcc181dc"
   },
   "outputs": [],
   "source": [
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = \"adam\"\n",
    "model = LeNet()\n",
    "model = model.build(numChannels=3, imgRows=150, imgCols=200,\n",
    "    numClasses=3)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "    metrics=[\"accuracy\"])\n",
    "print(\"[INFO] compiling DONE\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1786943,
     "status": "ok",
     "timestamp": 1590484710612,
     "user": {
      "displayName": "Itamar Bergfreund",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg2MDwlO6hYcHvwKV5xDf-9d_7Omi9UVhJtoP3XdQ=s64",
      "userId": "13778766431941037401"
     },
     "user_tz": -180
    },
    "id": "f9Fy2A7HJKAR",
    "outputId": "017d8d8a-500f-43bb-ca72-4e407051712f"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=200, epochs=20, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMcdEENVt4g9VzN/sFgftRh",
   "collapsed_sections": [],
   "name": "CNN - model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
