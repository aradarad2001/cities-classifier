{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dormeir999/cities-classifier/blob/master/VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsHRUi9tn_Cp"
      },
      "source": [
        "# Imports & setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO10Geax7UW3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import zipfile\n",
        "import glob\n",
        "import os\n",
        "from google.colab import drive\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, Flatten, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import numpy as np\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhDe56Yg7iFo",
        "outputId": "6561f20d-7438-486c-a5a0-b0f92b1aadb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNgXZnwr7lUz",
        "outputId": "86e4d869-b48b-4e2f-9ecf-86bbc4421a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "path_model = '/content/gdrive/My Drive/adidas/02-model'\n",
        "path_data =  '/content/gdrive/My Drive/adidas/01-data'\n",
        "os.listdir(path_model) # test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.ipynb_checkpoints',\n",
              " 'weights',\n",
              " 'logs',\n",
              " 'model',\n",
              " 'LeNet-Model',\n",
              " 'tf image classification.ipynb',\n",
              " 'Daniel Research Log.gdoc',\n",
              " 'GAN']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj-egQsq7nmP"
      },
      "source": [
        "# colab output:\n",
        "output_folder_path = '.'\n",
        "output_folder_path = Path(output_folder_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioKjZ8iR7xx6"
      },
      "source": [
        "# Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye3ipmY9PI7C"
      },
      "source": [
        "# get list of links from aws\n",
        "map_links = pd.read_csv(\n",
        "    'https://ww-research.s3-us-west-2.amazonaws.com/Arad/adidas/mapillary_links.csv'\n",
        "    ,header=None).iloc[:,0].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJS8U6iS70JO"
      },
      "source": [
        "def download_url(url, save_path=False, chunk_size=128):\n",
        "    \"downloads zip files to the folder that the notebook / python file is saved\"\n",
        "    if not save_path:\n",
        "        save_path = url.split('/')[-1]\n",
        "\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        with open(save_path, 'wb') as fd:\n",
        "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "                fd.write(chunk)\n",
        "    print(f\"file {save_path} succesfuly downloaded\")\n",
        "\n",
        "    \n",
        "def unzip_to_structure(zipfile_path, output_root_folder):\n",
        "    \"\"\"unzips files to specified output root folder with structure: \n",
        "        <output_root_folder> / <set_type> / <city> / <img_key>.jpg\"\"\"\n",
        "    output_root_folder = Path(output_root_folder)\n",
        "    file_parts = str(Path(zipfile_path).stem).split('_')\n",
        "    city = file_parts[0]\n",
        "    set_type = file_parts[1]\n",
        "    for s in ['train','test','val']:   \n",
        "      with zipfile.ZipFile(zipfile_path, 'r') as zip_ref:\n",
        "        if set_type == s:\n",
        "          zip_ref.extractall(output_root_folder / s )\n",
        "    print(f\"images from '{zipfile_path}' succesfuly unziped to '{output_root_folder / set_type / city}'\")\n",
        "\n",
        "\n",
        "def get_images(cities,output_path=output_folder_path,download_test=False):\n",
        "  \"\"\"gets all images for defined cities\n",
        "  param:: cities, array of cities\n",
        "  param:: output_path \"\"\"\n",
        "  linkz = []\n",
        "  if not download_test:\n",
        "    links = [l for l in map_links if 'test' not in l]\n",
        "  else:\n",
        "    links = map_links\n",
        "  for city in cities:\n",
        "    for link in links:\n",
        "      if city in link:\n",
        "        linkz.append(link) \n",
        "  # download files to current directory\n",
        "  for link in linkz:\n",
        "      download_url(link)\n",
        "  # unzip images to destination with format: \n",
        "  # <output_root_folder> / <set_type> / <city> / <img_key>.jpg\n",
        "  for link in linkz:\n",
        "      filename = Path(link).name\n",
        "      unzip_to_structure(filename,output_path)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-70cyn7zCeyu",
        "outputId": "9ded6dff-4415-49ac-809d-e5c36c4ba358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "# get data to current working dir (for changing dir got to top of the notebook):\n",
        "\n",
        "# available cities:\n",
        "my_cities = ['saopaulo','moscow','paris','manila','ottawa','austin','bangkok',\n",
        " 'sf','phoenix','melbourne','tokyo','goa','toronto','berlin', 'budapest',\n",
        " 'cph','helsinki','boston','amsterdam']\n",
        "\n",
        "# city selection:\n",
        "my_cities = ['saopaulo','paris','goa']\n",
        "\n",
        "# download images from aws:\n",
        "get_images(my_cities,download_test=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file saopaulo_train.zip succesfuly downloaded\n",
            "file saopaulo_val.zip succesfuly downloaded\n",
            "file saopaulo_test.zip succesfuly downloaded\n",
            "file paris_train.zip succesfuly downloaded\n",
            "file paris_val.zip succesfuly downloaded\n",
            "file paris_test.zip succesfuly downloaded\n",
            "file goa_train.zip succesfuly downloaded\n",
            "file goa_val.zip succesfuly downloaded\n",
            "file goa_test.zip succesfuly downloaded\n",
            "images from 'saopaulo_train.zip' succesfuly unziped to 'train/saopaulo'\n",
            "images from 'saopaulo_val.zip' succesfuly unziped to 'val/saopaulo'\n",
            "images from 'saopaulo_test.zip' succesfuly unziped to 'test/saopaulo'\n",
            "images from 'paris_train.zip' succesfuly unziped to 'train/paris'\n",
            "images from 'paris_val.zip' succesfuly unziped to 'val/paris'\n",
            "images from 'paris_test.zip' succesfuly unziped to 'test/paris'\n",
            "images from 'goa_train.zip' succesfuly unziped to 'train/goa'\n",
            "images from 'goa_val.zip' succesfuly unziped to 'val/goa'\n",
            "images from 'goa_test.zip' succesfuly unziped to 'test/goa'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcFqoO05vITp",
        "outputId": "3be1a23b-3e7e-4fcc-9b54-80b0f99530b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_data_to_numpy(file_list):\n",
        "    X = []\n",
        "    for filename in file_list :\n",
        "        img = img_to_array(load_img(filename, target_size = (150,150)))\n",
        "        X.append(img)\n",
        "    X = np.array(X).astype('float32')\n",
        "    # X = (X - X.mean()) / X.mean()\n",
        "    X = X / 255\n",
        "    return X\n",
        "\n",
        "import glob\n",
        "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "\n",
        "train_filelist = glob.glob('./train/*/*')\n",
        "val_filelist = glob.glob('./val/*/*')\n",
        "test_filelist = glob.glob('./train/*/*')\n",
        "len(train_filelist), len(val_filelist), len(test_filelist)\n",
        "\n",
        "#X_train = get_data(train_filelist)\n",
        "#X_val = get_data(val_filelist)\n",
        "#X_test = get_data(test_filelist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16966, 6516, 16966)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6PmqwnJ8j22"
      },
      "source": [
        "# Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l5EaSnFGayx"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import numpy as np\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBbHwtacvvCC"
      },
      "source": [
        "## Remove Outliers\n",
        "Some helpr functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYnMr_HTvyLd",
        "outputId": "a1627abe-f81d-4242-9b9c-08403f64c277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# I changed some layers here so that the final output will have the same output size as our images - 150x150x3\n",
        "\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "def decode_images_using_existing_model_weights(dataset,weights_path = '/weights/Auto-Encoders.ckpt'):\n",
        "  \"\"\"Recives a numpy dataset, returns a decoded dataset using the pre-trained \n",
        "  auto-enocder weights\"\"\"\n",
        "  # Create the CV for decoding\n",
        "  input_img = Input(shape=(150, 150, 3))  # adapt this if using `channels_first` image data format\n",
        "  x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "  x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "  x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "  #x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "  x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "  encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "  # at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "  x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "  x = UpSampling2D((2, 2))(x)\n",
        "  x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "  x = UpSampling2D((2, 2))(x)\n",
        "  x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "  #x = UpSampling2D((2, 2))(x)\n",
        "  decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "  autoencoder = Model(input_img, decoded)\n",
        "  autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')#, metrics=['accuracy'])\n",
        "  autoencoder.summary()\n",
        "\n",
        "  # load weights\n",
        "  checkpoint_filepath = path_model + weights_path\n",
        "  autoencoder.load_weights(checkpoint_filepath)\n",
        "  return autoencoder.predict(dataset)\n",
        "\n",
        "def clean_dataset_from_outlier(dataset, decoded_dataset, outlier_threshold=0.99):\n",
        "  \"\"\"Receives the origionl and the autoencoded numpy dataset, return cleaned dataset\n",
        "  without (default) 1% of images which are least similair to their decoded\n",
        "  image, and the indices for the outliers.\"\"\"\n",
        "  squred_error = np.power(X_train - decoded_dataset, 2)\n",
        "  channel_ax = 3\n",
        "  width_ax = 1\n",
        "  height_ax = 1\n",
        "  mse = np.mean(np.mean(squred_error,axis=(channel_ax,width_ax)),axis=height_ax)\n",
        "  mse_anomally_threshold = np.quantile(mse, outlier_threshold)\n",
        "  outliers_idx = np.where(mse > mse_anomally_threshold)\n",
        "  inliners_idx = np.where(mse <= mse_anomally_threshold)\n",
        "  return dataset[inliners_idx], outliers_idx[0]\n",
        "\n",
        "def show_origional_and_decoded(origional,decoded, n=5, show_decoded=True):\n",
        "  'Show random n images and their decoded images'\n",
        "  n+=1\n",
        "  images_index = np.random.choice(len(origional),n)\n",
        "  plt.figure(figsize=(20, 5))\n",
        "  for i in range(1,n):\n",
        "      ax = plt.subplot(1, n, i)\n",
        "      plt.imshow(origional[images_index[i]])\n",
        "      #plt.gray()\n",
        "      ax.get_xaxis().set_visible(False)\n",
        "      ax.get_yaxis().set_visible(False)\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=(20, 5))\n",
        "\n",
        "  if show_decoded:\n",
        "    for i in range(1,n):\n",
        "        ax = plt.subplot(1, n, i)\n",
        "        plt.imshow(decoded[images_index[i]])\n",
        "        #plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoknyEzrwyy-"
      },
      "source": [
        "* Uncomment the last line for cleaning a numpy dataset of images from outliers (using a threshold of percentage of outliers images).\n",
        "* Uncomment the two lines before for getting the decoded datasets - more gerneralized form of the photos, which might remove outliers pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdObOp69we5F"
      },
      "source": [
        "def remove_outliers(numpy_dataset, outlier_threshold=0.99):\n",
        "  'Recievs a numpy dataset, return the cleand dataset and the indices of outliers'\n",
        "  decoded_imgs = decode_images_using_existing_model_weights(numpy_dataset)\n",
        "  cleaned_dataset, outliers_idx = clean_dataset_from_outlier(numpy_dataset, decoded_imgs,outlier_threshold=0.98)\n",
        "  return cleaned_dataset, outliers_idx\n",
        "\n",
        "#decoded_imgs = decode_images_using_existing_model_weights(X_train)\n",
        "#show_origional_and_decoded(X_train,decoded_imgs, n=5)\n",
        "\n",
        "#X_train_cleaned, outlier_idx = remove_outliers(X_train, outlier_threshold=0.99)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AudqqPA1mmg-"
      },
      "source": [
        "## Set image and batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2UaWCWGHXvy"
      },
      "source": [
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "BATCH_SIZE = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lRUYXYXGbqh"
      },
      "source": [
        "train_dir = Path(\"./train\")\n",
        "val_dir = Path(\"./val\")\n",
        "test_dir = Path(\"./test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVSX8F3DGb0G",
        "outputId": "12789459-a821-4a06-c2b0-13395844a058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "CLASS_NAMES = np.array([item.name for item in train_dir.glob('*')])\n",
        "CLASS_NAMES"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['paris', 'goa', 'saopaulo'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgjjSbgtGb2p",
        "outputId": "60917575-2c64-4b97-dd3f-d03728969e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_image_count = len(list(train_dir.glob('*/*.jpg')))\n",
        "val_image_count = len(list(val_dir.glob('*/*.jpg')))\n",
        "test_image_count = len(list(test_dir.glob('*/*.jpg')))\n",
        "train_image_count, val_image_count, test_image_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16966, 6516, 6518)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qURaZHZ9ngIH"
      },
      "source": [
        "## Cached processing \\ tf.data.Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuVDcCppGjOU",
        "outputId": "fe871784-4bb2-4428-ce21-6589bb793716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list_train = tf.data.Dataset.list_files(str(train_dir/\"*/*\"))\n",
        "list_val = tf.data.Dataset.list_files(str(val_dir/\"*/*\"))\n",
        "list_test = tf.data.Dataset.list_files(str(test_dir/\"*/*\"),shuffle=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xuwBSznnQt2"
      },
      "source": [
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directory\n",
        "  return parts[-2] == CLASS_NAMES\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
        "\n",
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow0baCsHGjSc"
      },
      "source": [
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
        "  # This is a small dataset, only load it once, and keep it in memory.\n",
        "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
        "  # fit in memory.\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "  # Repeat forever\n",
        "  ds = ds.repeat()\n",
        "\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "  # is training.\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWgYOwjDGjQV"
      },
      "source": [
        "# Use Dataset.map to create a dataset of image, label pairs:\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "labeled_train = list_train.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "labeled_val = list_val.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "labeled_test = list_test.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "train_dataset = prepare_for_training(labeled_train)\n",
        "val_dataset = prepare_for_training(labeled_val)\n",
        "test_dataset = prepare_for_training(labeled_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc3UZoLSJuDj",
        "outputId": "65b45d1e-8f94-4108-e1b6-3090eff90f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, 224, 224, 3), (None, 3)), types: (tf.float32, tf.bool)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZOSE5pZV6Yz"
      },
      "source": [
        "## Augmentation attempt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InXbSCUfV4GB"
      },
      "source": [
        "def flip(img,lbl):\n",
        "\n",
        "  img = tf.image.random_flip_left_right(img)\n",
        "  img = tf.image.random_flip_up_down(img)\n",
        "  choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
        "  return img,lbl\n",
        "\n",
        "\n",
        "def color(img,lbl):\n",
        "\n",
        "    img = tf.image.random_hue(img, 0.08)\n",
        "    img = tf.image.random_saturation(img, 0.6, 1.6)\n",
        "    img = tf.image.random_brightness(img, 0.05)\n",
        "    img = tf.image.random_contrast(img, 0.7, 1.3)\n",
        "    choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
        "    return img,lbl\n",
        "\n",
        "\n",
        "def rotate(img,lbl):\n",
        "  img = tf.image.rot90(img, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "  choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
        "  return img ,lbl\n",
        "\n",
        "\n",
        "def zoom(img,lbl):\n",
        "\n",
        "    # Generate 20 crop settings, ranging from a 1% to 20% crop.\n",
        "    scales = list(np.arange(0.8, 1.0, 0.01))\n",
        "    boxes = np.zeros((len(scales), 4))\n",
        "\n",
        "    for i, scale in enumerate(scales):\n",
        "        x1 = y1 = 0.5 - (0.5 * scale)\n",
        "        x2 = y2 = 0.5 + (0.5 * scale)\n",
        "        boxes[i] = [x1, y1, x2, y2]\n",
        "\n",
        "    def random_crop(img):\n",
        "        # Create different crops for an image\n",
        "        crops = tf.image.crop_and_resize([img], boxes=boxes, box_indices=np.zeros(len(scales)), crop_size=(32, 32))\n",
        "        # Return a random crop\n",
        "        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n",
        "\n",
        "    choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
        "\n",
        "    # Only apply cropping 50% of the time\n",
        "    return tf.cond(choice < .25, lambda: img, lambda: random_crop(img)),lbl\n",
        "\n",
        "\n",
        "def clip(img,lbl):\n",
        "  img = tf.clip_by_value(img, 0, 1)\n",
        "  return img,lbl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8hT20eWV9qf"
      },
      "source": [
        "# augmentations = [flip, color, zoom, rotate]\n",
        "\n",
        "# # Add the augmentations to the dataset\n",
        "# for f in augmentations:\n",
        "#     augmented_train = labeled_train.map(f, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "# # Make sure that the values are still in [0, 1]\n",
        "# augmented_train = augmented_train.map(clip, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "# train_dataset = prepare_for_training(augmented_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkcNkqdBjj_I"
      },
      "source": [
        "# Build, complie & train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I9c7mNNkt24"
      },
      "source": [
        "## Initialize VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhpHt6yHCzR6",
        "outputId": "73098c68-d6b9-45b3-fa5e-8d21a54fe32c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# get train and test data:\n",
        "trdata = ImageDataGenerator()\n",
        "traindata = trdata.flow_from_directory(directory=\"train\",target_size=(224,224))\n",
        "tsdata = ImageDataGenerator()\n",
        "testdata = tsdata.flow_from_directory(directory=\"test\", target_size=(224,224))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 16966 images belonging to 3 classes.\n",
            "Found 6518 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXZuv5BTdPAF",
        "outputId": "4f772299-521f-4e2e-be3b-c4f9277d6251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        }
      },
      "source": [
        "plt.imshow(testdata[1][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-b052cb7c1116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5613\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5615\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5616\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (32, 224, 224, 3) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAMbElEQVR4nO3bcYikd33H8ffHXFNpGrWYFeTuNJFeGq+2kHRJU4SaYlouKdz9YZE7CG1KyKE1UlAKKZZU4l9WakG41l6pRAWNp3+UBU8CtZGAeDEbEmPuQmQ9bXNRmjOm/iMaQ7/9YybtZL+7mSd3szO39f2ChXme+e3Md4fhfc8881yqCkma9IpFDyDpwmMYJDWGQVJjGCQ1hkFSYxgkNVPDkOQTSZ5O8tgm9yfJx5KsJXk0yTWzH1PSPA05Yrgb2PcS998I7Bn/HAb+4fzHkrRIU8NQVfcDP3yJJQeAT9XICeA1SV4/qwElzd+OGTzGTuDJie0z433fX78wyWFGRxVccsklv3XVVVfN4Oklbeahhx76QVUtvdzfm0UYBquqo8BRgOXl5VpdXZ3n00s/d5L8+7n83iy+lXgK2D2xvWu8T9I2NYswrAB/PP524jrgR1XVPkZI2j6mfpRI8lngeuCyJGeAvwZ+AaCqPg4cB24C1oAfA3+6VcNKmo+pYaiqQ1PuL+A9M5tI0sJ55aOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6RmUBiS7EvyRJK1JHdscP8bktyX5OEkjya5afajSpqXqWFIchFwBLgR2AscSrJ33bK/Ao5V1dXAQeDvZz2opPkZcsRwLbBWVaer6jngHuDAujUFvGp8+9XA92Y3oqR5GxKGncCTE9tnxvsmfRC4OckZ4Djw3o0eKMnhJKtJVs+ePXsO40qah1mdfDwE3F1Vu4CbgE8naY9dVUerarmqlpeWlmb01JJmbUgYngJ2T2zvGu+bdCtwDKCqvga8ErhsFgNKmr8hYXgQ2JPkiiQXMzq5uLJuzX8AbwdI8mZGYfCzgrRNTQ1DVT0P3A7cCzzO6NuHk0nuSrJ/vOz9wG1JvgF8Frilqmqrhpa0tXYMWVRVxxmdVJzcd+fE7VPAW2c7mqRF8cpHSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUDApDkn1JnkiyluSOTda8M8mpJCeTfGa2Y0qapx3TFiS5CDgC/D5wBngwyUpVnZpYswf4S+CtVfVsktdt1cCStt6QI4ZrgbWqOl1VzwH3AAfWrbkNOFJVzwJU1dOzHVPSPA0Jw07gyYntM+N9k64Erkzy1SQnkuzb6IGSHE6ymmT17Nmz5zaxpC03q5OPO4A9wPXAIeCfkrxm/aKqOlpVy1W1vLS0NKOnljRrQ8LwFLB7YnvXeN+kM8BKVf2sqr4DfItRKCRtQ0PC8CCwJ8kVSS4GDgIr69b8C6OjBZJcxuijxekZzilpjqaGoaqeB24H7gUeB45V1ckkdyXZP152L/BMklPAfcBfVNUzWzW0pK2VqlrIEy8vL9fq6upCnlv6eZHkoapafrm/55WPkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySmkFhSLIvyRNJ1pLc8RLr3pGkkizPbkRJ8zY1DEkuAo4ANwJ7gUNJ9m6w7lLgz4EHZj2kpPkacsRwLbBWVaer6jngHuDABus+BHwY+MkM55O0AEPCsBN4cmL7zHjf/0pyDbC7qr74Ug+U5HCS1SSrZ8+efdnDSpqP8z75mOQVwEeB909bW1VHq2q5qpaXlpbO96klbZEhYXgK2D2xvWu87wWXAm8BvpLku8B1wIonIKXta0gYHgT2JLkiycXAQWDlhTur6kdVdVlVXV5VlwMngP1VtbolE0vaclPDUFXPA7cD9wKPA8eq6mSSu5Ls3+oBJc3fjiGLquo4cHzdvjs3WXv9+Y8laZG88lFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWDwpBkX5InkqwluWOD+9+X5FSSR5N8OckbZz+qpHmZGoYkFwFHgBuBvcChJHvXLXsYWK6q3wS+APzNrAeVND9DjhiuBdaq6nRVPQfcAxyYXFBV91XVj8ebJ4Bdsx1T0jwNCcNO4MmJ7TPjfZu5FfjSRnckOZxkNcnq2bNnh08paa5mevIxyc3AMvCRje6vqqNVtVxVy0tLS7N8akkztGPAmqeA3RPbu8b7XiTJDcAHgLdV1U9nM56kRRhyxPAgsCfJFUkuBg4CK5MLklwN/COwv6qenv2YkuZpahiq6nngduBe4HHgWFWdTHJXkv3jZR8Bfhn4fJJHkqxs8nCStoEhHyWoquPA8XX77py4fcOM55K0QF75KKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqRkUhiT7kjyRZC3JHRvc/4tJPje+/4Ekl896UEnzMzUMSS4CjgA3AnuBQ0n2rlt2K/BsVf0q8HfAh2c9qKT5GXLEcC2wVlWnq+o54B7gwLo1B4BPjm9/AXh7ksxuTEnztGPAmp3AkxPbZ4Df3mxNVT2f5EfAa4EfTC5Kchg4PN78aZLHzmXoBbmMdX/PBWw7zQrba97tNCvAr53LLw0Jw8xU1VHgKECS1apanufzn4/tNO92mhW217zbaVYYzXsuvzfko8RTwO6J7V3jfRuuSbIDeDXwzLkMJGnxhoThQWBPkiuSXAwcBFbWrVkB/mR8+4+Af6uqmt2YkuZp6keJ8TmD24F7gYuAT1TVySR3AatVtQL8M/DpJGvADxnFY5qj5zH3ImynebfTrLC95t1Os8I5zhv/YZe0nlc+SmoMg6Rmy8OwnS6nHjDr+5KcSvJoki8neeMi5pyY5yXnnVj3jiSVZGFfsw2ZNck7x6/vySSfmfeM62aZ9l54Q5L7kjw8fj/ctIg5x7N8IsnTm10XlJGPjf+WR5NcM/VBq2rLfhidrPw28CbgYuAbwN51a/4M+Pj49kHgc1s503nO+nvAL41vv3tRsw6dd7zuUuB+4ASwfKHOCuwBHgZ+Zbz9ugv5tWV0Uu/d49t7ge8ucN7fBa4BHtvk/puALwEBrgMemPaYW33EsJ0up546a1XdV1U/Hm+eYHRNx6IMeW0BPsTo/678ZJ7DrTNk1tuAI1X1LEBVPT3nGScNmbeAV41vvxr43hzne/EgVfcz+jZwMweAT9XICeA1SV7/Uo+51WHY6HLqnZutqarngRcup563IbNOupVRhRdl6rzjQ8bdVfXFeQ62gSGv7ZXAlUm+muREkn1zm64bMu8HgZuTnAGOA++dz2jn5OW+t+d7SfT/F0luBpaBty16ls0keQXwUeCWBY8y1A5GHyeuZ3Qkdn+S36iq/1roVJs7BNxdVX+b5HcYXcfzlqr670UPNgtbfcSwnS6nHjIrSW4APgDsr6qfzmm2jUyb91LgLcBXknyX0WfLlQWdgBzy2p4BVqrqZ1X1HeBbjEKxCEPmvRU4BlBVXwNeyeg/WF2IBr23X2SLT4rsAE4DV/B/J3F+fd2a9/Dik4/HFnQCZ8isVzM6KbVnETO+3HnXrf8Kizv5OOS13Qd8cnz7MkaHvq+9gOf9EnDL+PabGZ1jyALfD5ez+cnHP+TFJx+/PvXx5jDwTYzq/23gA+N9dzH6FxdGpf08sAZ8HXjTAl/cabP+K/CfwCPjn5VFzTpk3nVrFxaGga9tGH30OQV8Ezh4Ib+2jL6J+Oo4Go8Af7DAWT8LfB/4GaMjr1uBdwHvmnhtj4z/lm8OeR94SbSkxisfJTWGQVJjGCQ1hkFSYxgkNYZBUmMYJDX/AwqkUdV2nfELAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDIoT63U64pq",
        "outputId": "378b0123-b4c5-40f1-b3a4-27c0707f16f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "\n",
        "loaded_model = VGG16(weights='imagenet', include_top=True,\n",
        "              input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "vgg16 = Sequential()\n",
        "vgg16.add(loaded_model)\n",
        "vgg16.add(Flatten())\n",
        "vgg16.add(Dense(units=4096,activation=\"relu\"))\n",
        "vgg16.add(Dense(units=4096,activation=\"relu\"))\n",
        "vgg16.add(Dense(units=3, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "vgg16.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 9s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 1000)              138357544 \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              4100096   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12291     \n",
            "=================================================================\n",
            "Total params: 159,251,243\n",
            "Trainable params: 159,251,243\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQnDYk5LIKTj"
      },
      "source": [
        "loss = tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    label_smoothing=0,\n",
        "    reduction=\"auto\",\n",
        "    name=\"categorical_crossentropy\",\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow\n",
        "opt = Adam(lr=0.001)\n",
        "vgg16.compile(optimizer=opt, loss=loss, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3kIBZBADTvM",
        "outputId": "731a0058-e564-4bf0-856d-d3a29f53aaad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"gdrive/My Drive/adidas/02-model/weights/vgg16_1.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=4)\n",
        "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "hist = vgg16.fit_generator(steps_per_epoch=100,\n",
        "                           generator=traindata, \n",
        "                           validation_data= testdata, \n",
        "                           validation_steps=10,\n",
        "                           epochs=100,\n",
        "                           callbacks=[checkpoint,early])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/100\n",
            "100/100 [==============================] - 87s 865ms/step - loss: 1.0944 - accuracy: 0.3853 - val_loss: 1.1120 - val_accuracy: 0.2375\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 86s 864ms/step - loss: 1.0949 - accuracy: 0.3759 - val_loss: 1.1061 - val_accuracy: 0.3125\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 86s 865ms/step - loss: 1.0952 - accuracy: 0.3797 - val_loss: 1.1118 - val_accuracy: 0.2594\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0941 - accuracy: 0.3791\n",
            "Epoch 00004: val_loss improved from inf to 1.11387, saving model to gdrive/My Drive/adidas/02-model/weights/vgg16_1.h5\n",
            "100/100 [==============================] - 145s 1s/step - loss: 1.0941 - accuracy: 0.3791 - val_loss: 1.1139 - val_accuracy: 0.2812\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 87s 865ms/step - loss: 1.0942 - accuracy: 0.3816 - val_loss: 1.1074 - val_accuracy: 0.2812\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 88s 876ms/step - loss: 1.0962 - accuracy: 0.3674 - val_loss: 1.1188 - val_accuracy: 0.2562\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 85s 851ms/step - loss: 1.0957 - accuracy: 0.3713 - val_loss: 1.1039 - val_accuracy: 0.3187\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0935 - accuracy: 0.3819\n",
            "Epoch 00008: val_loss did not improve from 1.11387\n",
            "100/100 [==============================] - 85s 854ms/step - loss: 1.0935 - accuracy: 0.3819 - val_loss: 1.1151 - val_accuracy: 0.2594\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 86s 858ms/step - loss: 1.0963 - accuracy: 0.3681 - val_loss: 1.1098 - val_accuracy: 0.2656\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 86s 863ms/step - loss: 1.0934 - accuracy: 0.3859 - val_loss: 1.1132 - val_accuracy: 0.3000\n",
            "Epoch 11/100\n",
            " 98/100 [============================>.] - ETA: 1s - loss: 1.0942 - accuracy: 0.3804"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhnBEImL8oDW",
        "outputId": "de840112-3562-4893-84c9-c18c37962f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "print(\"[INFO] compiling model...\")\n",
        "opt = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
        "    name='Adam')\n",
        "metrics = [\"accuracy\"]\n",
        "loss = \"categorical_crossentropy\"\n",
        "\n",
        "# build model:\n",
        "model = LeNet().build(numChannels=3, \n",
        "                      imgRows=IMG_HEIGHT, \n",
        "                      imgCols=IMG_WIDTH, \n",
        "                      numClasses=len(CLASS_NAMES))\n",
        "\n",
        "\n",
        "# compile model:\n",
        "model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
        "\n",
        "print(\"[INFO] compiling DONE\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-258597cee0bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# build model:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m model = vgg16().build(numChannels=3, \n\u001b[0m\u001b[1;32m     10\u001b[0m                       \u001b[0mimgRows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_HEIGHT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                       \u001b[0mimgCols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m       raise ValueError(\n\u001b[0;32m--> 800\u001b[0;31m           'The first argument to `Layer.call` must always be passed.')\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0mcall_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The first argument to `Layer.call` must always be passed."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYyn_7ewkozv"
      },
      "source": [
        "## Setup model prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYAGy6glIZYY",
        "outputId": "e76813e1-8378-42e4-9349-e12556721147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# set callback:\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3,verbose=1)\n",
        "\n",
        "checkpoint_filepath = path_model + '/weights/CNN-03.ckpt'\n",
        "model_cp_cb = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True)\n",
        "checkpoint_filepath"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/adidas/02-model/weights/CNN-03.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s8APMG2WWj5"
      },
      "source": [
        "STEPS_PER_EPOCH = np.ceil(train_image_count/BATCH_SIZE)\n",
        "VAL_STEPS = np.ceil(val_image_count/BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWDM98xM7Vaf",
        "outputId": "220419eb-f9b6-4819-abc9-ed28425faa86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# # Evaluate the model before training\n",
        "# loss, acc = model.evaluate(train_dataset, verbose=1,steps=STEPS_PER_EPOCH)\n",
        "# print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17/17 [==============================] - 25s 1s/step - loss: 1.0865 - accuracy: 0.3747\n",
            "Untrained model, accuracy: 37.47%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skdk03nvjtcH",
        "outputId": "eb2a0828-8e8f-49d8-9270-16f5ddf1be59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        }
      },
      "source": [
        "# Setup Tensorboard - change from INACTIVE to Scalars after fit is done with the first epoch\n",
        "# It will update thrhought the training\n",
        "logdir = \"./logs\"\n",
        "!rm -rf ./logs\n",
        "%load_ext tensorboard\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=1)\n",
        "%tensorboard --logdir \"{logdir}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w3RtF-clBUG"
      },
      "source": [
        "# Train 🚂"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qV_BcLSB078",
        "outputId": "d363eaf5-af19-46b8-bd84-27de3f49276b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "es_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=3,verbose=1)\n",
        "\n",
        "history = model.fit(train_dataset, steps_per_epoch=STEPS_PER_EPOCH,\n",
        "          epochs=20, \n",
        "          verbose=1, \n",
        "          validation_data=val_dataset,validation_steps=VAL_STEPS,\n",
        "          callbacks=[model_cp_cb,tensorboard_callback,es_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "17/17 [==============================] - 15s 880ms/step - loss: 1.0406 - accuracy: 0.5149 - val_loss: 0.7224 - val_accuracy: 0.7121\n",
            "Epoch 2/20\n",
            "17/17 [==============================] - 3s 158ms/step - loss: 0.5420 - accuracy: 0.7852 - val_loss: 0.5007 - val_accuracy: 0.8131\n",
            "Epoch 3/20\n",
            "17/17 [==============================] - 3s 166ms/step - loss: 0.3351 - accuracy: 0.8793 - val_loss: 0.3981 - val_accuracy: 0.8620\n",
            "Epoch 4/20\n",
            "17/17 [==============================] - 3s 159ms/step - loss: 0.2286 - accuracy: 0.9210 - val_loss: 0.3900 - val_accuracy: 0.8763\n",
            "Epoch 5/20\n",
            "17/17 [==============================] - 3s 168ms/step - loss: 0.1722 - accuracy: 0.9397 - val_loss: 0.3701 - val_accuracy: 0.8785\n",
            "Epoch 6/20\n",
            "17/17 [==============================] - 2s 145ms/step - loss: 0.1322 - accuracy: 0.9551 - val_loss: 0.4158 - val_accuracy: 0.8753\n",
            "Epoch 7/20\n",
            "17/17 [==============================] - 2s 145ms/step - loss: 0.1057 - accuracy: 0.9644 - val_loss: 0.4639 - val_accuracy: 0.8645\n",
            "Epoch 8/20\n",
            "17/17 [==============================] - 3s 154ms/step - loss: 0.0915 - accuracy: 0.9692 - val_loss: 0.3756 - val_accuracy: 0.8923\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoXW6QdHlmlS"
      },
      "source": [
        "# Evaluate model on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQeVRd5NTrW5",
        "outputId": "309560be-b50a-4400-93ed-43eaf5e1dd56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePTxuBaplp0D",
        "outputId": "8f26842f-9dba-4ad6-ec76-9992dcc3d04a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get y_true and y_pred\n",
        "X_true = np.array([l[0].numpy() for l in list(labeled_test)])\n",
        "Y_true = np.array([list(l[1].numpy()) for l in list(labeled_test)])\n",
        "y_true = np.argmax(Y_true,axis=1)\n",
        "Y_pred = model.predict(np.array(X_true),verbose=1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "204/204 [==============================] - 1s 3ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sVkZXoDlp8S",
        "outputId": "a3806235-c087-4949-be92-39ba5c90c55a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "print('Classification Report')\n",
        "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    saopaulo       0.77      0.91      0.84      1771\n",
            "         goa       0.98      0.88      0.93      2427\n",
            "       paris       0.92      0.88      0.90      2320\n",
            "\n",
            "    accuracy                           0.89      6518\n",
            "   macro avg       0.89      0.89      0.89      6518\n",
            "weighted avg       0.90      0.89      0.89      6518\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5xjq7GZlp_B",
        "outputId": "fba10270-9f62-4f3c-b803-3a9e6b2fa2ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        }
      },
      "source": [
        "\n",
        "print('Confusion Matrix')\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(13,13))\n",
        "sns.heatmap(cm, annot=True, fmt='g',cmap = 'coolwarm',square=True,xticklabels=CLASS_NAMES,yticklabels=CLASS_NAMES)\n",
        "plt.yticks(rotation=0)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x936 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZvSBCwie38z"
      },
      "source": [
        "# Attempt at generalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2USUlHcFV07Q",
        "outputId": "50e79f6b-c6c2-4181-83a0-789010876dad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "# Setup generalization dataset (from drive)\n",
        "gen_dir = Path(path_data+'/generalization/')\n",
        "list_gen = tf.data.Dataset.list_files(str(gen_dir/\"*/*\"),shuffle=False)\n",
        "labeled_gen = list_gen.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "gen_dataset = prepare_for_training(labeled_gen)\n",
        "\n",
        "# Get y_true and y_pred\n",
        "X_true = np.array([l[0].numpy() for l in list(labeled_gen)])\n",
        "Y_true = np.array([list(l[1].numpy()) for l in list(labeled_gen)])\n",
        "y_true = np.argmax(Y_true,axis=1)\n",
        "Y_pred = model.predict(np.array(X_true),verbose=1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(13,13))\n",
        "sns.heatmap(cm, annot=True, fmt='g',cmap = 'coolwarm',square=True,xticklabels=CLASS_NAMES,yticklabels=CLASS_NAMES)\n",
        "plt.yticks(rotation=0)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x936 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9cm6JX7dfSS"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stWKxTtteOZV"
      },
      "source": [
        "def get_data(file_list,norm_range=[-1,1],img_size=(128,128)):\n",
        "    X = []\n",
        "    for filename in file_list :\n",
        "        img = img_to_array(load_img(filename, target_size = img_size))\n",
        "        X.append(img)\n",
        "    X = np.array(X).astype('float32')\n",
        "    if norm_range == [-1,1]:\n",
        "      X = (X - X.mean()) / X.std()\n",
        "      X = np.clip(X,-1,1)\n",
        "    elif norm_range == [0,1]:\n",
        "      X = X / 255\n",
        "    else:\n",
        "      print('bad range')\n",
        "      return\n",
        "    return X,X.mean(),X.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bim5GuHfZE5"
      },
      "source": [
        "paris_files = glob.glob('./train/paris/*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5hCCmLOfWzu"
      },
      "source": [
        "dataset,mean,std = get_data(paris_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iuKn_kyffNm",
        "outputId": "f5f3ee75-fb3c-4427-d600-6d9fb06ddb9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset.min(),dataset.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mgGTKaugbzb",
        "outputId": "4b194fb5-67c4-4878-8418-9f9f204512dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "# (X - X.mean()) / X.std()\n",
        "\n",
        "im = dataset[2]\n",
        "\n",
        "plt.imshow(im*im.std() + im.mean());\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-50055a32114f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# (X - X.mean()) / X.std()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wOlQFP9Jl5F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}